# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tHkegnZRMK5IvaFbkpXhGHmspFshBpJR
"""

!pip install numpy

import numpy as np
import math
from scipy.stats import multivariate_normal

from google.colab import files
uploaded = files.upload()

# Load dataset
filename = 'iris.data'
data = np.loadtxt(filename, delimiter=",", usecols=[0, 1, 2, 3])
labels = np.loadtxt(filename, delimiter=",", usecols=[4], dtype=str)

import numpy as np
from scipy.stats import multivariate_normal

# Load dataset
filename = 'iris.data'
data = np.loadtxt(filename, delimiter=",", usecols=[0, 1, 2, 3])
labels = np.loadtxt(filename, delimiter=",", usecols=[4], dtype=str)

# Number of clusters
k = 3

# Initialize clusters
def initialize_clusters(data, k):
    clusters = {}
    for i in range(k):
        start = i * 40
        end = start + 40
        mean = data[start:end].mean(axis=0)
        cov = np.cov(data[start:end].T)
        prior = 1 / k
        clusters[i] = {"mean": mean, "cov": cov, "prior": prior}
    return clusters

# E-Step: Calculate responsibilities
def expectation(data, clusters):
    responsibilities = np.zeros((data.shape[0], k))
    for i, cluster in clusters.items():
        responsibilities[:, i] = cluster["prior"] * multivariate_normal.pdf(
            data, mean=cluster["mean"], cov=cluster["cov"]
        )
    responsibilities /= responsibilities.sum(axis=1, keepdims=True)
    return responsibilities

# M-Step: Update parameters
def maximization(data, responsibilities):
    clusters = {}
    for i in range(k):
        resp = responsibilities[:, i]
        total_resp = resp.sum()
        mean = np.sum(data.T * resp, axis=1) / total_resp
        cov = np.cov(data.T, aweights=resp, ddof=0)
        prior = total_resp / data.shape[0]
        clusters[i] = {"mean": mean, "cov": cov, "prior": prior}
    return clusters

# Purity calculation
def compute_purity(cluster_membership, labels, k):
    label_map = {label: idx for idx, label in enumerate(np.unique(labels))}
    mapped_labels = np.array([label_map[label] for label in labels])

    purity = 0
    for i in range(k):
        members = cluster_membership[i]
        true_labels, counts = np.unique(mapped_labels[members], return_counts=True)
        purity += max(counts)
    return purity / len(labels)

# Main EM algorithm
clusters = initialize_clusters(data, k)
iteration = 0
convergence_threshold = 1e-6
old_means = np.array([clusters[i]["mean"] for i in range(k)])

while True:
    # E-Step
    responsibilities = expectation(data, clusters)

    # M-Step
    clusters = maximization(data, responsibilities)

    # Convergence check
    new_means = np.array([clusters[i]["mean"] for i in range(k)])
    if np.linalg.norm(new_means - old_means) < convergence_threshold:
        break
    old_means = new_means
    iteration += 1

# Prepare results
sorted_indices = np.argsort([np.linalg.norm(clusters[i]["mean"]) for i in range(k)])
sorted_clusters = {idx: clusters[i] for idx, i in enumerate(sorted_indices)}

# Final outputs
means = [sorted_clusters[i]["mean"] for i in range(k)]
covariances = [sorted_clusters[i]["cov"] for i in range(k)]
cluster_membership = {
    i: np.where(np.argmax(responsibilities, axis=1) == sorted_indices[i])[0]
    for i in range(k)
}
cluster_sizes = [len(cluster_membership[i]) for i in range(k)]
purity = compute_purity(cluster_membership, labels, k)

# Print results
print("Mean:")
for mean in means:
    print(np.round(mean, 3))

print("\nCovariance Matrices:")
for cov in covariances:
    print(np.round(cov, 3))
    print()

print(f"Iteration count: {iteration + 1}")

print("\nCluster Membership:")
for i in range(k):
    print(",".join(map(str, sorted(cluster_membership[i]))))

print(f"\nSize: {' '.join(map(str, cluster_sizes))}")
print(f"Purity: {round(purity, 3)}")

# Save results to PDF
with open("lastname-assign3.pdf", "w") as f:
    f.write("Mean:\n")
    for mean in means:
        f.write(f"{np.round(mean, 3)}\n")

    f.write("\nCovariance Matrices:\n")
    for cov in covariances:
        f.write(f"{np.round(cov, 3)}\n\n")

    f.write(f"Iteration count: {iteration + 1}\n")

    f.write("\nCluster Membership:\n")
    for i in range(k):
        f.write(",".join(map(str, sorted(cluster_membership[i]))) + "\n")

    f.write(f"\nSize: {' '.join(map(str, cluster_sizes))}\n")
    f.write(f"Purity: {round(purity, 3)}\n")